#!/usr/bin/python3
# -*- coding: utf-8 -*-
# Generate CVE OVAL from CVE metadata files
#
# Author: David Ries <ries@jovalcm.com>
# Author: Joy Latten <joy.latten@canonical.com>
# Author: Steve Beattie <steve.beattie@canonical.com>
# Copyright (C) 2015 Farnam Hall Ventures LLC
# Copyright (C) 2019 Canonical Ltd.
#
# This script is distributed under the terms and conditions of the GNU General
# Public License, Version 2 or later. See http://www.gnu.org/copyleft/gpl.html
# for details.
#
# Example usage:
# $ sudo apt-get install libopenscap8
# $ oscap info ./com.ubuntu.trusty.cve.oval.xml
# $ oscap oval generate report ./com.ubuntu.trusty.cve.oval.xml
#
# Requires 5.11.1 in /usr/share/openscap/schemas/oval/ but also openscap to
# support dpkg version comparisons. These will hopefully be part of openscap
# 1.3
# $ oscap oval eval --report /tmp/oval-report.html \
#     ./com.ubuntu.trusty.cve.oval.xml

from __future__ import print_function, unicode_literals

import argparse
import glob
import json
import os
import re
import sys

import apt_pkg
from cve_lib import (kernel_srcs, product_series, load_cve, PRODUCT_UBUNTU, all_releases, eol_releases, devel_release, release_parent, release_name, release_progenitor, needs_oval)
from kernel_lib import meta_kernels
import oval_lib

# cope with apt_pkg api changes.
if 'init_system' in dir(apt_pkg):
    apt_pkg.init_system()
else:
    apt_pkg.InitSystem()

supported_releases = []
for r in set(all_releases).difference(set(eol_releases)).difference(set([devel_release])):
    if needs_oval(r):
        supported_releases.append(r)
    parent = release_parent(r)
    if parent and parent not in supported_releases:
        supported_releases.append(parent)

default_cves_to_process = ['active/CVE-*', 'retired/CVE-*']

debug_level = 0

package_cache = None

def main():
    """ parse command line options and iterate through files to be processed
    """
    global debug_level
    global supported_releases

    # parse command line options
    parser = argparse.ArgumentParser(description='Generate CVE OVAL from '
                                     'CVE metadata files.')
    parser.add_argument('pathname', nargs='*',
                        help='pathname patterns (globs) specifying CVE '
                        'metadata files to be converted into OVAL '
                        '(default: "./active/CVE-*" "./retired/CVE-*")')
    parser.add_argument('--oci', action='store_true',
                        help='Also generate OVAL files for scanning Official Cloud Image manifests')
    parser.add_argument('--output-dir', nargs='?', default='./',
                        help='output directory for reports (default is ./)')
    parser.add_argument('--oci-output-dir', nargs='?',
                        help='output directory for OCI manifest OVAL files (default is to use the same directory as --output-dir)')
    parser.add_argument('--oci-prefix', nargs='?', default='oci.',
                        help='Prefix to use for OCI manifest OVAL files names (required if oci-output-dir is the same as output-dir)')
    parser.add_argument('--cve-prefix-dir', nargs='?', default='./',
                        help='location of CVE metadata files to process '
                        '(default is ./)')
    parser.add_argument('--no-progress', action='store_true',
                        help='do not show progress meter')
    parser.add_argument('--pkg-cache-dir', action='store', default='./',
                        help='cache location for binary packages')
    parser.add_argument('-d', '--debug', action='count', default=0,
                        help="report debugging information")
    parser.add_argument('--usn-oval', action='store_true',
                        help='generates oval from the USN database')
    parser.add_argument('--pkg-oval', action='store_true',
                        help='generates oval from the Package database')
    parser.add_argument('--usn-db-dir', default='./', type=str,
                        help='location of USN database.json to process '
                        '(default is ./)')
    parser.add_argument('--usn-number', default=None, type=str,
                        help='if passed specifics a USN for the oval_usn generator')
    parser.add_argument('--oval-release', default=None, type=str,
                        help='specifies a release to generate the oval usn')
    parser.add_argument('--packages', nargs='+', action='store', default=None,
                        help='generates oval for specific packages. Only for '
                        'CVE OVAL')
    parser.add_argument('--fixed-only', action='store_true',
                        help='only generate pkg oval for fixed CVEs')

    args = parser.parse_args()
    pathnames = args.pathname or default_cves_to_process
    debug_level = args.debug

    # debugging; caution, can expose credentials
    if debug_level >= 2:
        import httplib2
        httplib2.debuglevel = 1

    # create oval generators for each supported release
    outdir = './'
    if args.output_dir:
        outdir = args.output_dir
        if not os.path.isdir(outdir):
            raise FileNotFoundError("Could not find '%s'" % outdir)
    if args.oci:
        if args.oci_output_dir:
            ocioutdir = args.oci_output_dir
        else:
            ocioutdir = args.output_dir
        if not os.path.isdir(ocioutdir):
            raise FileNotFoundError("Could not find '%s'" % ocioutdir)
        ociprefix = args.oci_prefix
        if outdir == ocioutdir and len(ociprefix) < 1:
            raise ValueError("oci-prefix must be set when output-dir and oci-output-dir are the same")

    if args.usn_oval:
        if args.oci:
            generate_oval_usn(args.output_dir, args.usn_number, args.oval_release,
                              args.cve_prefix_dir, args.usn_db_dir, ociprefix, ocioutdir)
        else:
            generate_oval_usn(args.output_dir, args.usn_number, args.oval_release,
                              args.cve_prefix_dir, args.usn_db_dir)

        return

    releases = [args.oval_release] if args.oval_release else supported_releases
    supported_releases = releases
    cache = {}
    for release in releases:
        cve_cache = {}
        cache.update({release: get_package_cache(args.pkg_cache_dir, release)})

    if args.pkg_oval:
        if args.oci:
            generate_oval_package(outdir, args.cve_prefix_dir, cache, cve_cache, args.oci, args.no_progress, args.packages, pathnames, args.fixed_only, ociprefix, ocioutdir)
        else:
            generate_oval_package(outdir, args.cve_prefix_dir, cache, cve_cache, args.oci, args.no_progress, args.packages, pathnames, args.fixed_only)
        return

    if args.oci:
        generate_oval_cve(outdir, args.cve_prefix_dir, cache, args.oci,
                          args.no_progress, args.packages, pathnames,  ociprefix, ocioutdir)
    else:
        generate_oval_cve(outdir, args.cve_prefix_dir, cache, args.oci,
                          args.no_progress, args.packages, pathnames)
    return


# given a status generated by parse_package_status(), duplicate it for a
# different source package, computing binary packages for the new source
# package
def duplicate_package_status(release, package, original_status, cache, override_version=None):
    copied_status = {}
    copied_status['status'] = original_status['status']
    copied_status['note'] = original_status['note']
    if override_version:
        copied_status['fix-version'] = override_version
    elif 'fix-version' in original_status:
        copied_status['fix-version'] = original_status['fix-version']

    if 'bin-pkgs' in original_status:
        copied_status['bin-pkgs'] = original_status['bin-pkgs']

    return copied_status


# returns True if we should ignore this source package; primarily used
# for -edge kernels
def ignore_source_package(source):
    if re.match('linux-.*-edge$', source):
        return True
    return False


def parse_cve_file(filepath, cache, pkg_filter=None):
    """ parse CVE data file into a dictionary using cve_lib """

    cve_header_data = {
        'Candidate': '',
        'CRD': '',
        'PublicDate': '',
        'PublicDateAtUSN': '',
        'References': [get_cve_url(filepath)],
        'Description': '',
        'Ubuntu-Description': '',
        'Notes': '',
        'Mitigation': '',
        'Bugs': [],
        'Priority': '',
        'Discovered-by': '',
        'Assigned-to': '',
        'CVSS': '',
        'Unknown-Fields': [],
        'Source-note': filepath
    }

    data = load_cve(filepath)
    # first try a naive translation of fields
    for f in cve_header_data:
        try:
            cve_header_data[f] = data[f]
        except KeyError:
            pass

    # then handle any particular fields which are expected to have a
    # different format
    cve_header_data['Description'] = cve_header_data['Description'].strip().replace('\n', ' ')
    cve_header_data['Ubuntu-Description'] = cve_header_data['Ubuntu-Description'].strip().replace('\n', ' ')
    cve_header_data['References'] = [ref.strip() for ref in cve_header_data['References'].split('\n') if len(ref.strip()) > 0]
    cve_header_data['References'].insert(0, get_cve_url(filepath))
    cve_header_data['Bugs'] = [bug.strip() for bug in cve_header_data['Bugs'].split('\n') if len(bug.strip()) > 0]
    cve_header_data['Notes'] = ' '.join(user + '> ' + note.replace('\n', ' ') for user, note in cve_header_data['Notes'])
    cve_header_data['Priority'] = cve_header_data['Priority'][0]
    packages = {}
    for pkg in data['pkgs']:
        if ignore_source_package(pkg):
            continue
        if pkg_filter:
            if pkg not in pkg_filter:
                continue

        packages[pkg] = {'Releases': {},
                         'Priority': '',
                         'Tags': []}
        for rel in data['pkgs'][pkg]:
            if rel in ['upstream', 'devel']:
                continue
            if rel not in supported_releases:
                continue
            state, details = data['pkgs'][pkg][rel]
            packages[pkg]['Releases'][rel] = oval_lib.CVEPkgRelEntry.parse_package_status(rel, pkg, state, details, filepath, cache)

    # add supplemental packages; usually kernels only need this special case.
    for package in [name for name in packages if name in kernel_srcs]:
        for release in [
            rel for rel in packages[package]['Releases']
            if packages[package]['Releases'][rel]['status'] != 'not-applicable'
        ]:
            # add signed package
            # handle signed package of subprojects without needing to have them in kernel_lib
            progenitor = release_progenitor(release)
            if progenitor:
                signed_pkg = meta_kernels.get_signed(progenitor, package, quiet=(debug_level < 1))
            else:
                signed_pkg = meta_kernels.get_signed(release, package, quiet=(debug_level < 1))
            if signed_pkg:
                if signed_pkg not in packages:
                    packages[signed_pkg] = {
                        'Priority': packages[package]['Priority'],
                        'Tags': packages[package]['Tags'],
                        'Releases': {}
                    }
                if release not in packages[signed_pkg]['Releases']:
                    packages[signed_pkg]['Releases'][release] = \
                        duplicate_package_status(release, signed_pkg, packages[package]['Releases'][release], cache)

    # if subproject is based on an ubuntu release
    for pkg in packages:
        # if subproject is DNE for a given package, then copy parent's status
        for rel in packages[pkg]['Releases']:
            parent = release_parent(rel)
            if parent and parent in packages[pkg]['Releases']:
                if packages[pkg]['Releases'][parent]['status'] != 'not-applicable' and packages[pkg]['Releases'][rel]['status'] == 'not-applicable':
                    packages[pkg]['Releases'][rel] = \
                        duplicate_package_status(parent, pkg, packages[pkg]['Releases'][parent], cache)
                    # this is needed for update instructions
                    progenitor = release_progenitor(parent)
                    if progenitor and progenitor in packages[pkg]['Releases']:
                        if packages[pkg]['Releases'][parent]['status'] == packages[pkg]['Releases'][progenitor]['status']:
                            packages[pkg]['Releases'][rel]['parent'] = progenitor
                        else:
                            packages[pkg]['Releases'][rel]['parent'] = parent
                    else:
                        packages[pkg]['Releases'][rel]['parent'] = parent
        # if supported release not in CVE file, then copy parent's status
        for rel in supported_releases:
            if rel not in packages[pkg]['Releases']:
                parent = release_parent(rel)
                if parent and parent in packages[pkg]['Releases']:
                    packages[pkg]['Releases'][rel] = \
                        duplicate_package_status(parent, pkg, packages[pkg]['Releases'][parent], cache)
                    # this is needed for update instructions
                    progenitor = release_progenitor(parent)
                    if progenitor and progenitor in packages[pkg]['Releases']:
                        if packages[pkg]['Releases'][parent]['status'] == packages[pkg]['Releases'][progenitor]['status']:
                            packages[pkg]['Releases'][rel]['parent'] = progenitor
                        else:
                            packages[pkg]['Releases'][rel]['parent'] = parent
                    else:
                        packages[pkg]['Releases'][rel]['parent'] = parent

    return {'header': cve_header_data, 'packages': packages}


def get_cve_url(filepath):
    """ returns a url to CVE data from a filepath """
    path = os.path.realpath(filepath).split(os.sep)
    url = "https://ubuntu.com/security"
    cve = path[-1]
    return "%s/%s" % (url, cve)


def warn(message):
    """ print a warning message """
    sys.stdout.write('\rWARNING: {0}\n'.format(message))

def error(message):
    """ print a error message """
    sys.stderr.write('\rERROR: {0}\n'.format(message))
    sys.exit(1)

def debug(message):
    """ print a debuging message """
    if debug_level > 0:
        sys.stdout.write('\rDEBUG: {0}\n'.format(message))

def progress_bar(current, total, size=20):
    """ show a simple progress bar on the CLI """
    current_percent = float(current) / total
    hashes = '#' * int(round(current_percent * size))
    spaces = ' ' * (size - len(hashes))
    sys.stdout.write('\rProgress: [{0}] {1}% ({2} of {3} CVEs processed)'.format(hashes + spaces, int(round(current_percent * 100)), current, total))
    if (current == total):
        sys.stdout.write('\n')

    sys.stdout.flush()

def prepend_usn_to_id(usn_database, usn_id):
    if re.search(r'^[0-9]+-[0-9]$', usn_id):
        usn_database[usn_id]['id'] = 'USN-' + usn_id

# loads cve package cache <release>-pkg-cache.json based given path to it.
# To get the cache proceed as: $UCT/scripts/fetch-db <release>-pkg-cache.json pkg-cache
def get_package_cache(pkg_cache_dir, release):
    data = {}
    for filename in glob.glob(os.path.join(pkg_cache_dir, release.replace('/', '_') + '-pkg-cache.json')):
        debug(f"Opening and reading cache file {filename}")
        with open(filename, 'r') as f:
            data = json.load(f)

    return data

# loads usn database.json based given a path to it.
# To get the database proceed as: $UCT/scripts/fetch-db database.json.bz2
def get_usn_database(usn_db_dir):
    data = {}
    for filename in glob.glob(os.path.join(usn_db_dir, 'database*.json')):
        with open(filename, 'r') as f:
            data.update(json.load(f))

    return data

# Usage:
# for a given release only:
#   ./generate-oval --usn-oval --usn-db-dir ~/usndb --usn-oval-release=focal --output-dir /tmp/oval_usn
# for all the releases:
#   ./generate-oval --usn-oval --usn-db-dir ~/usndb --output-dir /tmp/oval_usn
# for a specific release and USN-number
#   ./generate-oval --usn-oval --usn-db-dir ~/usndb --usn-oval-release=focal --usn-number=1234
# WARNING:
#  be sure the release you are passing is in the usn-number passed
#  otherwise it will generate an oval file without the usn info.
def generate_oval_usn(outdir, usn, usn_release, cve_dir, usn_db_dir, ociprefix=None, ocioutdir=None):
    # Get the usn database.json data
    usn_database = get_usn_database(usn_db_dir)
    if not usn_database:
        error("Error getting local USN database. Please, run '$UCT/scripts/fetch-db database.json.bz2' to retrieve the database and try again.")

    if usn:
        if usn not in usn_database:
            error("Please enter a valid USN number or update your database.json and try again")

    if usn_release:
        if usn_release not in supported_releases:
            error("Please enter a valid release name.")

    # Create OvalGeneratorUSN objects
    ovals = []
    # Does the oval for just a specific given release
    if usn_release:
        ovals.append(oval_lib.OvalGeneratorUSN(usn_release, release_name(usn_release), outdir, cve_dir))
        # Also produce oval generator object for OCI
        if ocioutdir:
            ovals.append(oval_lib.OvalGeneratorUSN(usn_release, release_name(usn_release), ocioutdir,
                                                   cve_dir, ociprefix, 'oci'))
    else:
        for release in supported_releases:
            # for now we don't differentiate products (e.g. esm) in the USN DB
            product, series = product_series(release)
            if product != PRODUCT_UBUNTU:
                continue

            ovals.append(oval_lib.OvalGeneratorUSN(release, release_name(release), outdir, cve_dir))
            # Also produce oval generator object for OCI
            if ocioutdir:
                ovals.append(oval_lib.OvalGeneratorUSN(release, release_name(release), ocioutdir,
                                                       cve_dir, ociprefix,
                                                       'oci'))

    # Generate OVAL USN data
    if usn:
        prepend_usn_to_id(usn_database, usn)
        for oval in ovals:
            oval.generate_usn_oval(usn_database[usn], usn_database[usn]['id'], cve_dir)
    else:
        for usn in sorted(usn_database.keys()):
            prepend_usn_to_id(usn_database, usn)
            for oval in ovals:
                oval.generate_usn_oval(usn_database[usn], usn_database[usn]['id'], cve_dir)

    for oval in ovals:
        oval.write_oval_elements()

    return True

def generate_oval_package(outdir, cve_prefix_dir, pkg_cache, cve_cache, oci, no_progress, packages, pathnames, fixed_only, ociprefix='', ocioutdir=None):
    for release in supported_releases:
        if not no_progress:
            print(f'[*] Generating OVAL for packages in release {release}')
        ov = oval_lib.OvalGeneratorPkg(release, release_name(release), pathnames, packages, not no_progress, pkg_cache=pkg_cache, fixed_only=fixed_only, cve_cache=cve_cache, oval_format='oci' if oci else 'dpkg', outdir=outdir, cve_prefix_dir=cve_prefix_dir, prefix=ociprefix)
        ov.generate_oval()

        if oci:
            ov.oval_format = 'dpkg'
            ov.generate_oval()

        if not no_progress:
            print(f'[X] Done generating OVAL for packages in release {release}')

def generate_oval_cve(outdir, cve_prefix_dir, cache, oci, no_progress, packages, pathnames, ociprefix=None, ocioutdir=None):
    ovals = dict()
    for release in supported_releases:
        # we can have nested parent releases
        parent = release_progenitor(release)
        index = '{0}_dpkg'.format(release)
        ovals[index] = oval_lib.OvalGeneratorCVE(release, release_name(release), parent, warn, outdir, prefix='', oval_format='dpkg')
        ovals[index].add_release_applicability_definition()
        if oci:
            index = '{0}_oci'.format(release)
            ovals[index] = oval_lib.OvalGeneratorCVE(release, release_name(release), parent, warn, ocioutdir, prefix=ociprefix, oval_format='oci')
            ovals[index].add_release_applicability_definition()

    # loop through all CVE data files
    files = []
    for pathname in pathnames:
        files = files + glob.glob(os.path.join(cve_prefix_dir, pathname))
    files.sort()

    pkg_filter = None
    if packages:
        pkg_filter = packages

    files_count = len(files)
    for i_file, filepath in enumerate(files):
        cve_data = parse_cve_file(filepath, cache, pkg_filter)
        # skip CVEs without packages for supported releases
        if not cve_data['packages']:
            if not no_progress:
                progress_bar(i_file + 1, files_count)
            continue

        for i in ovals:
            ovals[i].generate_cve_definition(cve_data)

        if not no_progress:
            progress_bar(i_file + 1, files_count)

    for i in ovals:
        ovals[i].write_to_file()

if __name__ == '__main__':
    main()
